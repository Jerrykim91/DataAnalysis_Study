{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 판다스 입문 _07\n",
    "\n",
    "- https://github.com/easysIT/doit_pandas/blob/master/notebook/07_done.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 넓은 데이터 -  melt 메서드 사용\n",
    "- 컬럼으로 된 아이들을 로우(열)로 변환하는 작업을 하는 메서드\n",
    "- 데이터프레임의 열은 파이썬의 변수와 비슷한 역활을 함 \n",
    "- 데이터프레임의 열이 옆으로 길게 늘어선 형태가 됨 => 넓은 데이터 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -  melt 메서드 사용\n",
    "- 지정한 열의 데이터를 모두 행으로 정리 \n",
    "    - id_vars    : 위치를 그대로 유지할 열의 이름을 지정 \n",
    "    - value_vars : 행으로 위치를 변경할 열의 이름을 지정\n",
    "    - var_name : value_vars로 위치를 변경한 열의 이름을 지정 \n",
    "    - value_name: var_name으로 위치를 변경한 열의 데이터를 저장한 열의 이름을 지정 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1개의 열만 고정하고 나머지 열을 행으로 바꾸기\n",
    "- 사용데이터 : 미국의 소득과 종교 from pew Research Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pew = pd.read_csv('../data/pew.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k  $50-75k  \\\n",
      "0            Agnostic     27       34       60       81       76      137   \n",
      "1             Atheist     12       27       37       52       35       70   \n",
      "2            Buddhist     27       21       30       34       33       58   \n",
      "3            Catholic    418      617      732      670      638     1116   \n",
      "4  Don’t know/refused     15       14       15       11       10       35   \n",
      "\n",
      "   $75-100k  $100-150k  >150k  Don't know/refused  \n",
      "0       122        109     84                  96  \n",
      "1        73         59     74                  76  \n",
      "2        62         39     53                  54  \n",
      "3       949        792    633                1489  \n",
      "4        21         17     18                 116  \n"
     ]
    }
   ],
   "source": [
    "print(pew.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['religion', '<$10k', '$10-20k', '$20-30k', '$30-40k', '$40-50k',\n",
      "       '$50-75k', '$75-100k', '$100-150k', '>150k', 'Don't know/refused'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(pew.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k\n",
      "0                  Agnostic     27       34       60       81       76\n",
      "1                   Atheist     12       27       37       52       35\n",
      "2                  Buddhist     27       21       30       34       33\n",
      "3                  Catholic    418      617      732      670      638\n",
      "4        Don’t know/refused     15       14       15       11       10\n",
      "5          Evangelical Prot    575      869     1064      982      881\n",
      "6                     Hindu      1        9        7        9       11\n",
      "7   Historically Black Prot    228      244      236      238      197\n",
      "8         Jehovah's Witness     20       27       24       24       21\n",
      "9                    Jewish     19       19       25       25       30\n",
      "10            Mainline Prot    289      495      619      655      651\n",
      "11                   Mormon     29       40       48       51       56\n",
      "12                   Muslim      6        7        9       10        9\n",
      "13                 Orthodox     13       17       23       32       32\n",
      "14          Other Christian      9        7       11       13       13\n",
      "15             Other Faiths     20       33       40       46       49\n",
      "16    Other World Religions      5        2        3        4        2\n",
      "17             Unaffiliated    217      299      374      365      341\n"
     ]
    }
   ],
   "source": [
    "# 6개의 열만 출력 => 소득과 종교 데이터 출력 \n",
    "#  소득정보가 열을 구성 => 소득 정보를열을 행 데이터로 \n",
    "print(pew.iloc[:,0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             religion variable  value\n",
      "0            Agnostic    <$10k     27\n",
      "1             Atheist    <$10k     12\n",
      "2            Buddhist    <$10k     27\n",
      "3            Catholic    <$10k    418\n",
      "4  Don’t know/refused    <$10k     15\n"
     ]
    }
   ],
   "source": [
    "# religion열을 고정하여 피벗 \n",
    "pew_long = pd.melt(pew, id_vars='religion')\n",
    "print(pew_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             religion income  count\n",
      "0            Agnostic  <$10k     27\n",
      "1             Atheist  <$10k     12\n",
      "2            Buddhist  <$10k     27\n",
      "3            Catholic  <$10k    418\n",
      "4  Don’t know/refused  <$10k     15\n"
     ]
    }
   ],
   "source": [
    "# variable, value 열이름 바꾸기 \n",
    "pew_long = pd.melt(pew, id_vars='religion', var_name='income', value_name='count')\n",
    "print(pew_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2개 이상의 열을 고정하고 나머지 열을 행으로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빌보드 \n",
    "billboard = pd.read_csv('../data/billboard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered  wk1   wk2  \\\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   87  82.0   \n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   91  87.0   \n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08   81  70.0   \n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21   76  76.0   \n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15   57  34.0   \n",
      "\n",
      "    wk3   wk4   wk5   wk6   wk7   wk8   wk9  wk10  wk11  \n",
      "0  72.0  77.0  87.0  94.0  99.0   NaN   NaN   NaN   NaN  \n",
      "1  92.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "2  68.0  67.0  66.0  57.0  54.0  53.0  51.0  51.0  51.0  \n",
      "3  72.0  69.0  67.0  65.0  55.0  59.0  62.0  61.0  61.0  \n",
      "4  25.0  17.0  17.0  31.0  36.0  49.0  53.0  57.0  64.0  \n"
     ]
    }
   ],
   "source": [
    "print(billboard.iloc[0:5,0:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered week  rating\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1    91.0\n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk1    81.0\n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk1    76.0\n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk1    57.0\n"
     ]
    }
   ],
   "source": [
    "# 열고정 ['year', 'artist', 'track', 'time', 'date.entered']\n",
    "# 나머지 열을 피벗 \n",
    "billboard_long = pd.melt(billboard, id_vars=['year', 'artist', 'track', 'time', 'date.entered'], var_name='week', value_name='rating')\n",
    "\n",
    "print(billboard_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       year                artist                    track  time date.entered  \\\n",
      "0      2000                 2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   \n",
      "1      2000               2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   \n",
      "2      2000          3 Doors Down               Kryptonite  3:53   2000-04-08   \n",
      "3      2000          3 Doors Down                    Loser  4:24   2000-10-21   \n",
      "4      2000              504 Boyz            Wobble Wobble  3:35   2000-04-15   \n",
      "5      2000                  98^0  Give Me Just One Nig...  3:24   2000-08-19   \n",
      "6      2000               A*Teens            Dancing Queen  3:44   2000-07-08   \n",
      "7      2000               Aaliyah            I Don't Wanna  4:15   2000-01-29   \n",
      "8      2000               Aaliyah                Try Again  4:03   2000-03-18   \n",
      "9      2000        Adams, Yolanda            Open My Heart  5:30   2000-08-26   \n",
      "10     2000         Adkins, Trace                     More  3:05   2000-04-29   \n",
      "11     2000   Aguilera, Christina  Come On Over Baby (A...  3:38   2000-08-05   \n",
      "12     2000   Aguilera, Christina            I Turn To You  4:00   2000-04-15   \n",
      "13     2000   Aguilera, Christina        What A Girl Wants  3:18   1999-11-27   \n",
      "14     2000          Alice Deejay         Better Off Alone  6:50   2000-04-08   \n",
      "15     2000           Allan, Gary  Smoke Rings In The D...  4:18   2000-01-22   \n",
      "16     2000                 Amber                   Sexual  4:38   1999-07-17   \n",
      "17     2000             Anastacia           I'm Outta Love  4:01   2000-04-01   \n",
      "18     2000         Anthony, Marc              My Baby You  3:59   2000-09-16   \n",
      "19     2000         Anthony, Marc           You Sang To Me  3:50   2000-02-26   \n",
      "20     2000                 Avant            My First Love  4:28   2000-11-04   \n",
      "21     2000                 Avant                Separated  4:13   2000-04-29   \n",
      "22     2000                 BBMak                Back Here  3:35   2000-04-29   \n",
      "23     2000  Backstreet Boys, The        Shape Of My Heart  3:49   2000-10-14   \n",
      "24     2000  Backstreet Boys, The  Show Me The Meaning ...  3:54   2000-01-01   \n",
      "25     2000  Backstreet Boys, The                  The One  3:46   2000-05-27   \n",
      "26     2000          Badu, Erkyah                 Bag Lady  5:03   2000-08-19   \n",
      "27     2000              Baha Men     Who Let The Dogs Out  3:17   2000-07-22   \n",
      "28     2000      Barenaked Ladies                 Pinch Me  3:46   2000-09-09   \n",
      "29     2000            Beenie Man          Girls Dem Sugar  4:17   2000-10-21   \n",
      "...     ...                   ...                      ...   ...          ...   \n",
      "24062  2000          Thomas, Carl                Emotional  4:31   2000-11-25   \n",
      "24063  2000          Thomas, Carl                   I Wish  3:50   2000-03-25   \n",
      "24064  2000          Thomas, Carl              Summer Rain  4:57   2000-09-23   \n",
      "24065  2000         Tippin, Aaron                Kiss This  2:53   2000-08-26   \n",
      "24066  2000                 Train            Meet Virginia  3:55   1999-10-09   \n",
      "24067  2000           Trick Daddy                  Shut Up  4:17   2000-05-20   \n",
      "24068  2000                 Trina                Pull Over  2:58   2000-09-09   \n",
      "24069  2000         Tritt, Travis       Best Of Intentions  4:15   2000-08-19   \n",
      "24070  2000               Tuesday                   I Know  4:06   2000-12-30   \n",
      "24071  2000          Urban, Keith          Your Everything  4:10   2000-07-15   \n",
      "24072  2000                 Usher            Pop Ya Collar  3:36   2000-11-04   \n",
      "24073  2000          Vassar, Phil                  Carlene  4:07   2000-03-04   \n",
      "24074  2000          Vassar, Phil  Just Another Day In ...  3:54   2000-09-30   \n",
      "24075  2000      Vertical Horizon      Everything You Want  4:01   2000-01-22   \n",
      "24076  2000      Vertical Horizon             You're A God  3:45   2000-08-26   \n",
      "24077  2000             Vitamin C  Graduation (Friends ...  4:23   2000-04-15   \n",
      "24078  2000             Vitamin C                 The Itch  3:30   2000-12-02   \n",
      "24079  2000          Walker, Clay        Live, Laugh, Love  4:06   1999-12-04   \n",
      "24080  2000          Walker, Clay        The Chain Of Love  5:03   2000-04-15   \n",
      "24081  2000      Wallflowers, The              Sleepwalker  3:29   2000-10-28   \n",
      "24082  2000              Westlife           Swear It Again  4:07   2000-04-01   \n",
      "24083  2000      Williams, Robbie                   Angels  3:56   1999-11-20   \n",
      "24084  2000           Wills, Mark              Back At One  4:00   2000-01-15   \n",
      "24085  2000        Worley, Darryl  When You Need My Lov...  3:35   2000-06-17   \n",
      "24086  2000         Wright, Chely                   It Was  3:51   2000-03-04   \n",
      "24087  2000           Yankee Grey     Another Nine Minutes  3:10   2000-04-29   \n",
      "24088  2000      Yearwood, Trisha          Real Live Woman  3:55   2000-04-01   \n",
      "24089  2000       Ying Yang Twins  Whistle While You Tw...  4:19   2000-03-18   \n",
      "24090  2000         Zombie Nation            Kernkraft 400  3:30   2000-09-02   \n",
      "24091  2000       matchbox twenty                     Bent  4:12   2000-04-29   \n",
      "\n",
      "       week  rating  \n",
      "0       wk1    87.0  \n",
      "1       wk1    91.0  \n",
      "2       wk1    81.0  \n",
      "3       wk1    76.0  \n",
      "4       wk1    57.0  \n",
      "5       wk1    51.0  \n",
      "6       wk1    97.0  \n",
      "7       wk1    84.0  \n",
      "8       wk1    59.0  \n",
      "9       wk1    76.0  \n",
      "10      wk1    84.0  \n",
      "11      wk1    57.0  \n",
      "12      wk1    50.0  \n",
      "13      wk1    71.0  \n",
      "14      wk1    79.0  \n",
      "15      wk1    80.0  \n",
      "16      wk1    99.0  \n",
      "17      wk1    92.0  \n",
      "18      wk1    82.0  \n",
      "19      wk1    77.0  \n",
      "20      wk1    70.0  \n",
      "21      wk1    62.0  \n",
      "22      wk1    99.0  \n",
      "23      wk1    39.0  \n",
      "24      wk1    74.0  \n",
      "25      wk1    58.0  \n",
      "26      wk1    67.0  \n",
      "27      wk1    99.0  \n",
      "28      wk1    77.0  \n",
      "29      wk1    72.0  \n",
      "...     ...     ...  \n",
      "24062  wk76     NaN  \n",
      "24063  wk76     NaN  \n",
      "24064  wk76     NaN  \n",
      "24065  wk76     NaN  \n",
      "24066  wk76     NaN  \n",
      "24067  wk76     NaN  \n",
      "24068  wk76     NaN  \n",
      "24069  wk76     NaN  \n",
      "24070  wk76     NaN  \n",
      "24071  wk76     NaN  \n",
      "24072  wk76     NaN  \n",
      "24073  wk76     NaN  \n",
      "24074  wk76     NaN  \n",
      "24075  wk76     NaN  \n",
      "24076  wk76     NaN  \n",
      "24077  wk76     NaN  \n",
      "24078  wk76     NaN  \n",
      "24079  wk76     NaN  \n",
      "24080  wk76     NaN  \n",
      "24081  wk76     NaN  \n",
      "24082  wk76     NaN  \n",
      "24083  wk76     NaN  \n",
      "24084  wk76     NaN  \n",
      "24085  wk76     NaN  \n",
      "24086  wk76     NaN  \n",
      "24087  wk76     NaN  \n",
      "24088  wk76     NaN  \n",
      "24089  wk76     NaN  \n",
      "24090  wk76     NaN  \n",
      "24091  wk76     NaN  \n",
      "\n",
      "[24092 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# 구조를 변경 \n",
    "print(billboard_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 열이름 관리 \n",
    "- 하나의 열이 여러의미를 가지는 경우 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ebola 데이터 집합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ebola = pd.read_csv('../data/country_timeseries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Day', 'Cases_Guinea', 'Cases_Liberia', 'Cases_SierraLeone',\n",
      "       'Cases_Nigeria', 'Cases_Senegal', 'Cases_UnitedStates', 'Cases_Spain',\n",
      "       'Cases_Mali', 'Deaths_Guinea', 'Deaths_Liberia', 'Deaths_SierraLeone',\n",
      "       'Deaths_Nigeria', 'Deaths_Senegal', 'Deaths_UnitedStates',\n",
      "       'Deaths_Spain', 'Deaths_Mali'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(ebola.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day  Cases_Guinea  Cases_Liberia  Deaths_Guinea  Deaths_Liberia\n",
      "0    1/5/2015  289        2776.0            NaN         1786.0             NaN\n",
      "1    1/4/2015  288        2775.0            NaN         1781.0             NaN\n",
      "2    1/3/2015  287        2769.0         8166.0         1767.0          3496.0\n",
      "3    1/2/2015  286           NaN         8157.0            NaN          3496.0\n",
      "4  12/31/2014  284        2730.0         8115.0         1739.0          3471.0\n"
     ]
    }
   ],
   "source": [
    "print(ebola.iloc[:5,[0,1,2,3,10,11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0\n",
      "3    1/2/2015  286  Cases_Guinea     NaN\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0\n"
     ]
    }
   ],
   "source": [
    "# Date,Day 고정하고 나머지행 피벗 \n",
    "# => 사망자 수를 행으로 볼수 있어서 편리   \n",
    "ebola_long = pd.melt(ebola, id_vars=['Date', 'Day'])\n",
    "print(ebola_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(ebola_long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 열이름 분리\n",
    "- split이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 언더바 기준으로 쪼겔 것 \n",
    "variable_split = ebola_long.variable.str.split('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0\n",
      "3    1/2/2015  286  Cases_Guinea     NaN\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0\n"
     ]
    }
   ],
   "source": [
    "print(ebola_long[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [Cases, Guinea]\n",
      "1    [Cases, Guinea]\n",
      "2    [Cases, Guinea]\n",
      "3    [Cases, Guinea]\n",
      "4    [Cases, Guinea]\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(variable_split[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사각 괄호 //// ??? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# 자료형 => 시리즈 \n",
    "print(type(variable_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# 각 시리즈에 저장된 값의 자료형은 리스트 \n",
    "print(type(variable_split[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get 메소드 => 0,1인덱스를 한번에 추출 \n",
    "status_values = variable_split.str.get(0) \n",
    "country_values = variable_split.str.get(1)\n",
    "# print(status_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Cases\n",
      "1    Cases\n",
      "2    Cases\n",
      "3    Cases\n",
      "4    Cases\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(status_values[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1952,)\n"
     ]
    }
   ],
   "source": [
    "# 열길이 확인 \n",
    "print(status_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1947    Deaths\n",
      "1948    Deaths\n",
      "1949    Deaths\n",
      "1950    Deaths\n",
      "1951    Deaths\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(status_values[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Guinea\n",
      "1    Guinea\n",
      "2    Guinea\n",
      "3    Guinea\n",
      "4    Guinea\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(country_values[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1952,)\n"
     ]
    }
   ],
   "source": [
    "print(country_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1947    Mali\n",
      "1948    Mali\n",
      "1949    Mali\n",
      "1950    Mali\n",
      "1951    Mali\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(country_values[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0\n",
      "3    1/2/2015  286  Cases_Guinea     NaN\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0\n"
     ]
    }
   ],
   "source": [
    "print(ebola_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# status,country 열 이름으로 데이터 프레임에 추가한 코드 \n",
    "ebola_long['status'] = status_values\n",
    "ebola_long['country'] = country_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value status country\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0  Cases  Guinea\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0  Cases  Guinea\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0  Cases  Guinea\n",
      "3    1/2/2015  286  Cases_Guinea     NaN  Cases  Guinea\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0  Cases  Guinea\n"
     ]
    }
   ],
   "source": [
    "print(ebola_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 또 다른 방법 \n",
    "### concat 메서드를 응용하여 데이터프레임에 열 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value status country status country\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0  Cases  Guinea  Cases  Guinea\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0  Cases  Guinea  Cases  Guinea\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0  Cases  Guinea  Cases  Guinea\n",
      "3    1/2/2015  286  Cases_Guinea     NaN  Cases  Guinea  Cases  Guinea\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0  Cases  Guinea  Cases  Guinea\n"
     ]
    }
   ],
   "source": [
    "variable_split = ebola_long.variable.str.split('_', expand=True) \n",
    "variable_split.columns = ['status', 'country'] \n",
    "ebola_parsed = pd.concat([ebola_long, variable_split], axis=1)\n",
    "\n",
    "print(ebola_parsed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 여러 열 하나로 정리 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기상 데이터의 여러 열을 하나로 정리하기\n",
    "    ─ melt, pivot_table 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  year  month element  d1    d2    d3  d4    d5  d6  d7\n",
      "0  MX17004  2010      1    tmax NaN   NaN   NaN NaN   NaN NaN NaN\n",
      "1  MX17004  2010      1    tmin NaN   NaN   NaN NaN   NaN NaN NaN\n",
      "2  MX17004  2010      2    tmax NaN  27.3  24.1 NaN   NaN NaN NaN\n",
      "3  MX17004  2010      2    tmin NaN  14.4  14.4 NaN   NaN NaN NaN\n",
      "4  MX17004  2010      3    tmax NaN   NaN   NaN NaN  32.1 NaN NaN\n",
      "5  MX17004  2010      3    tmin NaN   NaN   NaN NaN  14.2 NaN NaN\n",
      "6  MX17004  2010      4    tmax NaN   NaN   NaN NaN   NaN NaN NaN\n",
      "7  MX17004  2010      4    tmin NaN   NaN   NaN NaN   NaN NaN NaN\n",
      "8  MX17004  2010      5    tmax NaN   NaN   NaN NaN   NaN NaN NaN\n",
      "9  MX17004  2010      5    tmin NaN   NaN   NaN NaN   NaN NaN NaN\n"
     ]
    }
   ],
   "source": [
    "# 데이터 가져오고 확인 \n",
    "weather = pd.read_csv('../data/weather.csv') \n",
    "print(weather.iloc[:10, :11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  year  month element day  temp\n",
      "0  MX17004  2010      1    tmax  d1   NaN\n",
      "1  MX17004  2010      1    tmin  d1   NaN\n",
      "2  MX17004  2010      2    tmax  d1   NaN\n",
      "3  MX17004  2010      2    tmin  d1   NaN\n",
      "4  MX17004  2010      3    tmax  d1   NaN\n",
      "5  MX17004  2010      3    tmin  d1   NaN\n",
      "6  MX17004  2010      4    tmax  d1   NaN\n",
      "7  MX17004  2010      4    tmin  d1   NaN\n",
      "8  MX17004  2010      5    tmax  d1   NaN\n",
      "9  MX17004  2010      5    tmin  d1   NaN\n"
     ]
    }
   ],
   "source": [
    "# melt\n",
    "# 날짜 열을 행데이터로 피벗 \n",
    "weather_melt = pd.melt(weather, id_vars=['id', 'year', 'month', 'element'], var_name='day', value_name='temp') \n",
    "print(weather_melt.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다시 집고 넘어가기 \n",
    "**피벗 테이블(pivot_table)이란?**     \n",
    "- 데이터 열 중에서 두 개의 열을 각각 행 인덱스, 열 인덱스로 사용하여      \n",
    "    => 데이터를 조회하여 펼쳐놓은 것     \n",
    "    => pivot메서드 사용       \n",
    "    \n",
    "\n",
    "[참고](https://datascienceschool.net/view-notebook/76dcd63bba2c4959af15bec41b197e7c/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# element => 컬럼으로 \n",
    "# weather_melt 참고해서 이해 \n",
    "weather_tidy = weather_melt.pivot_table(\n",
    "    index=['id', 'year', 'month', 'day'], \n",
    "    columns='element', \n",
    "    values='temp'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element                 tmax  tmin\n",
      "id      year month day            \n",
      "MX17004 2010 1     d1    NaN   NaN\n",
      "                   d10   NaN   NaN\n",
      "                   d11   NaN   NaN\n",
      "                   d12   NaN   NaN\n",
      "                   d13   NaN   NaN\n",
      "                   d14   NaN   NaN\n",
      "                   d15   NaN   NaN\n",
      "                   d16   NaN   NaN\n",
      "                   d17   NaN   NaN\n",
      "                   d18   NaN   NaN\n",
      "                   d19   NaN   NaN\n",
      "                   d2    NaN   NaN\n",
      "                   d20   NaN   NaN\n",
      "                   d21   NaN   NaN\n",
      "                   d22   NaN   NaN\n",
      "                   d23   NaN   NaN\n",
      "                   d24   NaN   NaN\n",
      "                   d25   NaN   NaN\n",
      "                   d26   NaN   NaN\n",
      "                   d27   NaN   NaN\n",
      "                   d28   NaN   NaN\n",
      "                   d29   NaN   NaN\n",
      "                   d3    NaN   NaN\n",
      "                   d30  27.8  14.5\n",
      "                   d31   NaN   NaN\n",
      "                   d4    NaN   NaN\n",
      "                   d5    NaN   NaN\n",
      "                   d6    NaN   NaN\n",
      "                   d7    NaN   NaN\n",
      "                   d8    NaN   NaN\n",
      "...                      ...   ...\n",
      "             12    d10   NaN   NaN\n",
      "                   d11   NaN   NaN\n",
      "                   d12   NaN   NaN\n",
      "                   d13   NaN   NaN\n",
      "                   d14   NaN   NaN\n",
      "                   d15   NaN   NaN\n",
      "                   d16   NaN   NaN\n",
      "                   d17   NaN   NaN\n",
      "                   d18   NaN   NaN\n",
      "                   d19   NaN   NaN\n",
      "                   d2    NaN   NaN\n",
      "                   d20   NaN   NaN\n",
      "                   d21   NaN   NaN\n",
      "                   d22   NaN   NaN\n",
      "                   d23   NaN   NaN\n",
      "                   d24   NaN   NaN\n",
      "                   d25   NaN   NaN\n",
      "                   d26   NaN   NaN\n",
      "                   d27   NaN   NaN\n",
      "                   d28   NaN   NaN\n",
      "                   d29   NaN   NaN\n",
      "                   d3    NaN   NaN\n",
      "                   d30   NaN   NaN\n",
      "                   d31   NaN   NaN\n",
      "                   d4    NaN   NaN\n",
      "                   d5    NaN   NaN\n",
      "                   d6   27.8  10.5\n",
      "                   d7    NaN   NaN\n",
      "                   d8    NaN   NaN\n",
      "                   d9    NaN   NaN\n",
      "\n",
      "[341 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(weather_tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element       id  year  month  day  tmax  tmin\n",
      "0        MX17004  2010      1   d1   NaN   NaN\n",
      "1        MX17004  2010      1  d10   NaN   NaN\n",
      "2        MX17004  2010      1  d11   NaN   NaN\n",
      "3        MX17004  2010      1  d12   NaN   NaN\n",
      "4        MX17004  2010      1  d13   NaN   NaN\n",
      "5        MX17004  2010      1  d14   NaN   NaN\n",
      "6        MX17004  2010      1  d15   NaN   NaN\n",
      "7        MX17004  2010      1  d16   NaN   NaN\n",
      "8        MX17004  2010      1  d17   NaN   NaN\n",
      "9        MX17004  2010      1  d18   NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "# 데이터 프레임의 인덱스를 reset_index메서드로 새로 지정한것 \n",
    "weather_tidy_flat = weather_tidy.reset_index() \n",
    "print(weather_tidy_flat.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 빌보드 차트의 중복 데이터 처리\n",
    "- 열 데이터의 반복 => 따로 관리하는것이 좋음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard = pd.read_csv('../data/billboard.csv')\n",
    "billboard_long = pd.melt(billboard, id_vars=['year', 'artist', 'track', 'time', 'date.entered'], var_name='week', value_name='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 7)\n"
     ]
    }
   ],
   "source": [
    "print(billboard_long.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered week  rating\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1    91.0\n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk1    81.0\n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk1    76.0\n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk1    57.0\n"
     ]
    }
   ],
   "source": [
    "print(billboard_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year        artist  track  time date.entered  week  rating\n",
      "3     2000  3 Doors Down  Loser  4:24   2000-10-21   wk1    76.0\n",
      "320   2000  3 Doors Down  Loser  4:24   2000-10-21   wk2    76.0\n",
      "637   2000  3 Doors Down  Loser  4:24   2000-10-21   wk3    72.0\n",
      "954   2000  3 Doors Down  Loser  4:24   2000-10-21   wk4    69.0\n",
      "1271  2000  3 Doors Down  Loser  4:24   2000-10-21   wk5    67.0\n",
      "1588  2000  3 Doors Down  Loser  4:24   2000-10-21   wk6    65.0\n",
      "1905  2000  3 Doors Down  Loser  4:24   2000-10-21   wk7    55.0\n",
      "2222  2000  3 Doors Down  Loser  4:24   2000-10-21   wk8    59.0\n",
      "2539  2000  3 Doors Down  Loser  4:24   2000-10-21   wk9    62.0\n",
      "2856  2000  3 Doors Down  Loser  4:24   2000-10-21  wk10    61.0\n"
     ]
    }
   ],
   "source": [
    "# 트렉 : 노레제목 \n",
    "# Loser => 중복 데이터가 상당히 많음 \n",
    "print(billboard_long[billboard_long.track == 'Loser'].head(10))\n",
    "# 가수는 고유한 값이기 대문에 따로 관리하는것이 데이터의 일관성을 유지하는 데 도움 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 4)\n"
     ]
    }
   ],
   "source": [
    "billboard_songs = billboard_long[['year', 'artist', 'track', 'time']] \n",
    "print(billboard_songs.shape)\n",
    "# 중복 데이터를 가지고 있는 열은 따로모아 새로운 데이터 프레임에 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        False\n",
      "1        False\n",
      "2        False\n",
      "3        False\n",
      "4        False\n",
      "5        False\n",
      "6        False\n",
      "7        False\n",
      "8        False\n",
      "9        False\n",
      "10       False\n",
      "11       False\n",
      "12       False\n",
      "13       False\n",
      "14       False\n",
      "15       False\n",
      "16       False\n",
      "17       False\n",
      "18       False\n",
      "19       False\n",
      "20       False\n",
      "21       False\n",
      "22       False\n",
      "23       False\n",
      "24       False\n",
      "25       False\n",
      "26       False\n",
      "27       False\n",
      "28       False\n",
      "29       False\n",
      "         ...  \n",
      "24062     True\n",
      "24063     True\n",
      "24064     True\n",
      "24065     True\n",
      "24066     True\n",
      "24067     True\n",
      "24068     True\n",
      "24069     True\n",
      "24070     True\n",
      "24071     True\n",
      "24072     True\n",
      "24073     True\n",
      "24074     True\n",
      "24075     True\n",
      "24076     True\n",
      "24077     True\n",
      "24078     True\n",
      "24079     True\n",
      "24080     True\n",
      "24081     True\n",
      "24082     True\n",
      "24083     True\n",
      "24084     True\n",
      "24085     True\n",
      "24086     True\n",
      "24087     True\n",
      "24088     True\n",
      "24089     True\n",
      "24090     True\n",
      "24091     True\n",
      "Length: 24092, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# 불린으로 중복 체크 \n",
    "print(billboard_songs.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(317, 4)\n"
     ]
    }
   ],
   "source": [
    "# 반복된거를 삭제 \n",
    "#  데이터 프레임의 중복 데이터 삭제 \n",
    "# drop_duplicates\n",
    "billboard_songs = billboard_songs.drop_duplicates() \n",
    "print(billboard_songs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year          artist                    track  time  id\n",
      "0  2000           2 Pac  Baby Don't Cry (Keep...  4:22   0\n",
      "1  2000         2Ge+her  The Hardest Part Of ...  3:15   1\n",
      "2  2000    3 Doors Down               Kryptonite  3:53   2\n",
      "3  2000    3 Doors Down                    Loser  4:24   3\n",
      "4  2000        504 Boyz            Wobble Wobble  3:35   4\n",
      "5  2000            98^0  Give Me Just One Nig...  3:24   5\n",
      "6  2000         A*Teens            Dancing Queen  3:44   6\n",
      "7  2000         Aaliyah            I Don't Wanna  4:15   7\n",
      "8  2000         Aaliyah                Try Again  4:03   8\n",
      "9  2000  Adams, Yolanda            Open My Heart  5:30   9\n"
     ]
    }
   ],
   "source": [
    "# 중복을 제거한 데이터프레임에 아이디 추가 \n",
    "billboard_songs['id'] = range(len(billboard_songs))\n",
    "# 데이터 확인 => id 값 ghkrdls \n",
    "print(billboard_songs.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 8)\n"
     ]
    }
   ],
   "source": [
    "# merge사용 => 노래정보와 주간 순위데이터 합함\n",
    "billboard_ratings = billboard_long.merge(billboard_songs, on=['year', 'artist', 'track', 'time'])\n",
    "print(billboard_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year artist                    track  time date.entered week  rating  id\n",
      "0  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0   0\n",
      "1  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk2    82.0   0\n",
      "2  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk3    72.0   0\n",
      "3  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk4    77.0   0\n",
      "4  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk5    87.0   0\n"
     ]
    }
   ],
   "source": [
    "print(billboard_ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 대용량 데이터 처리 \n",
    "- 용량이 많을 경우 여러개로 나누어 저장\n",
    "- 그러면 여러개로 나누어진 데이터를 불러와 사용 \n",
    "### 뉴욕 택시 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  깃에 안올라가서 다시 돌릴때 다운 받으삼 \n",
    "# import os \n",
    "# import urllib.request\n",
    "\n",
    "# # 네트워크 상태에 따라 5 ~ 15분이 소요됩니다.\n",
    "# with open('../data/raw_data_urls.txt', 'r') as data_urls:\n",
    "#     for line, url in enumerate(data_urls):\n",
    "#         # 140개중 5개만 가지고옴 ㄴ\n",
    "#         if line == 5:\n",
    "#             break \n",
    "#         fn = url.split('/')[-1].strip()\n",
    "#         fp = os.path.join('', '../data', fn)\n",
    "#         print(url)\n",
    "#         print(fp)\n",
    "#         urllib.request.urlretrieve(url, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import glob \n",
    "nyc_taxi_data = glob.glob('../data/fhv_*') \n",
    "print(nyc_taxi_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-eaecb93ca708>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 데이터 프레임으로 저장  => 양이 많아서 저장하는데 시간 소요 될수 있음\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtaxi1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnyc_taxi_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtaxi2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnyc_taxi_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtaxi3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnyc_taxi_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtaxi4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnyc_taxi_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# 데이터 프레임으로 저장  => 양이 많아서 저장하는데 시간 소요 될수 있음 \n",
    "taxi1 = pd.read_csv(nyc_taxi_data[0])\n",
    "taxi2 = pd.read_csv(nyc_taxi_data[1]) \n",
    "taxi3 = pd.read_csv(nyc_taxi_data[2]) \n",
    "taxi4 = pd.read_csv(nyc_taxi_data[3]) \n",
    "taxi5 = pd.read_csv(nyc_taxi_data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 읽어드리기 \n",
    "print(taxi1.head(n=2)) \n",
    "print(taxi2.head(n=2)) \n",
    "print(taxi3.head(n=2)) \n",
    "print(taxi4.head(n=2)) \n",
    "print(taxi5.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 크기 확인 \n",
    "print(taxi1.shape)\n",
    "print(taxi2.shape)\n",
    "print(taxi3.shape)\n",
    "print(taxi4.shape)\n",
    "print(taxi5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat으로 데이터 합치기 \n",
    "taxi = pd.concat([taxi1, taxi2, taxi3, taxi4, taxi5])\n",
    "# [taxi1, taxi2, taxi3, taxi4, taxi5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 데이터 크기 확인 \n",
    "print(taxi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(taxi.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 반복문으로 데이터 준비\n",
    "- 응용하면 단 몇 줄의 코드로 데이터를 준비가능     \n",
    "- 반복문으로 읽어서 -> 리스트에 이어 붙이면        \n",
    "-> 순서대로 리스트에서 데이터 프레임으로 저장   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_taxi_df = []\n",
    "\n",
    "for csv_filename in nyc_taxi_data:\n",
    "#     print(csv_filename)\n",
    "    df = pd.read_csv(csv_filename)\n",
    "#     print(df)\n",
    "    list_taxi_df.append(df)\n",
    "\n",
    "print(len(list_taxi_df))\n",
    "# 왜 ? 5개?\n",
    "# 붙이는 파일 개수인것 같음 \n",
    "# print(list_taxi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(list_taxi_df[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_taxi_df[0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_loop_concat = pd.concat(list_taxi_df)\n",
    "print(taxi_loop_concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(taxi.equals(taxi_loop_concat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 넓은 데이터를 분석하기 좋게 => 피벗부터 중복데이터를 처리하는 방법과 열을 하나로 합치는 실습ㄲ지 진행 \n",
    "# 데이터 분석에는 깔끔한 데이터는 매우 중요함 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
